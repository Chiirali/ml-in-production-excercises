{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "native-dinner",
   "metadata": {},
   "source": [
    "# Excercise 4: Containerize Model\n",
    "\n",
    "Now that we have a model, we can build a container around it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-trademark",
   "metadata": {},
   "source": [
    "## Excercise 1: Evaluate Dummy Service \n",
    "\n",
    "Currently our frontend calls a dummy service to check if a user is eligible. \n",
    "\n",
    "Our dummy service already provides the basic infrastrucure to serve a real sklearn model.\n",
    "\n",
    "Read through the `DummyModel.py`, `requirements.txt` and the `Dockerfile` at `services/dummy` and try to understand whats going on.\n",
    "\n",
    "Questions\n",
    "- What is the predicion of our dummy service?\n",
    "- How could you adapt our dummy service to serve our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-pakistan",
   "metadata": {},
   "source": [
    "## Excercise 2: Create wrapper around our model\n",
    "\n",
    "Now that we understand our dummy service, we want to load our previously trained model. \n",
    "\n",
    "1. Copy dummy service\n",
    "  \n",
    "  `services/dummy/DummyModel.py`,`services/dummy/requirements.txt` and `services/dummy/Dockerfile` to \n",
    "  `services/eligibilty/EligiblityModel.py`, `services/eligibilty/requirements.py` and `services/eligibilty/Dockerfile`.\n",
    "2. Copy our model from `model/elibility_model.joblib` to `services/eligibilty/elibility_model.joblib`\n",
    "3. Adjust `EligibilityModel.py` to load our pipeline from the joblib file and call our pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-classics",
   "metadata": {},
   "source": [
    "## Excercise 3: Build docker image and start it\n",
    "\n",
    "To serve our model from Docker we need to adjust the Dockerfile at `services/dummy/Dockerfile`:\n",
    "\n",
    "Change `ENV MODEL_NAME DummyModel` to `ENV MODEL_NAME EligibilityModel`\n",
    "\n",
    "And adjust the `docker-compose.yml` to use our new elibility service instead of dummy:\n",
    "\n",
    "Change \n",
    "```yml\n",
    "eligibility-service:\n",
    "    build: ./services/dummy\n",
    "``` \n",
    "to \n",
    "\n",
    "```yml\n",
    "eligibility-service:\n",
    "    build: ./services/eligibility\n",
    "``` \n",
    "\n",
    "Then restart docker-compose: `docker-compose down` and `docker-compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-amateur",
   "metadata": {},
   "source": [
    "## Excercise 4: Call our eligiblity service\n",
    "\n",
    "Our eligiblity service now exposes our model using a REST API. We can call it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "progressive-sixth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-05 13:54:52--  http://localhost:8100/predict\r\n",
      "Resolving localhost (localhost)... ::1, 127.0.0.1\r\n",
      "Connecting to localhost (localhost)|::1|:8100... failed: Connection refused.\r\n",
      "Connecting to localhost (localhost)|127.0.0.1|:8100... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 46 [application/json]\r\n",
      "Saving to: ‘STDOUT’\r\n",
      "\r\n",
      "\r",
      "-                     0%[                    ]       0  --.-KB/s               {\"data\":{\"names\":[],\"ndarray\":[1]},\"meta\":{}}\r\n",
      "\r",
      "-                   100%[===================>]      46  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2021-05-05 13:54:52 (11.1 MB/s) - written to stdout [46/46]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -O- http://eligiblity-service:8100/predict --post-data '{\"data\": { \"ndarray\": [[25000, 189625]]}}' --header='Content-Type:application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-adapter",
   "metadata": {},
   "source": [
    "If you receive a succssful response \"200 OK\" you can switch to our frontend and test our service like an end user: http://localhost:8000/#order"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
